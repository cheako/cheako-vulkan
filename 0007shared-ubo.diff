diff -bNur 0006multi-model/0_vert.glsl 0007shared-ubo/0_vert.glsl
--- 0006multi-model/0_vert.glsl	2019-03-03 15:08:52.168916321 -0600
+++ 0007shared-ubo/0_vert.glsl	2019-03-03 15:08:52.172915452 -0600
@@ -15,12 +15,16 @@
 {
 	mat4 model;
 	mat4 bones[MAX_BONES];
+} ubo;
+
+layout (binding = 2) uniform SUBO 
+{
 	mat4 vp;
 	vec3 lightPos;
 	float pada;
 	vec3 viewPos;
 	float padb;
-} ubo;
+} subo;
 
 layout (location = 0) out vec2 outUV;
 layout (location = 1) out vec3 outNormal;
@@ -41,10 +45,10 @@
 	outUV = inUV;
 
 	mat4 skinPos = ubo.model * boneTransform;
-	gl_Position = ubo.vp * skinPos * vec4(inPos, 1.0);
+	gl_Position = subo.vp * skinPos * vec4(inPos, 1.0);
 
 	vec4 pos = skinPos * vec4(inPos, 1.0);
 	outNormal = inverse(transpose(mat3(skinPos))) * inNormal;
-	outLightVec = ubo.lightPos - pos.xyz;
-	outViewVec = ubo.viewPos - pos.xyz;
+	outLightVec = subo.lightPos - pos.xyz;
+	outViewVec = subo.viewPos - pos.xyz;
 }
diff -bNur 0006multi-model/data_bulk.h 0007shared-ubo/data_bulk.h
--- 0006multi-model/data_bulk.h	2019-03-03 15:08:52.168916321 -0600
+++ 0007shared-ubo/data_bulk.h	2019-03-03 15:08:52.172915452 -0600
@@ -4,13 +4,7 @@
 // Must not be higher than same const in skinning shader
 #define MAX_BONES 64
 
-typedef struct
-{
+typedef struct {
         mat4 model;
         mat4 bones[MAX_BONES];
-        mat4 vp;
-        vec3 lightPos;
-        float pada;
-        vec3 viewPos;
-        float padb;
 } material_0_ubo_t;
diff -bNur 0006multi-model/data.h 0007shared-ubo/data.h
--- 0006multi-model/data.h	2019-03-03 15:08:52.168916321 -0600
+++ 0007shared-ubo/data.h	2019-03-03 15:08:52.172915452 -0600
@@ -31,6 +31,8 @@
 extern const struct data_model_index *data_model_index;
 extern const VkDeviceSize data_model_index_size;
 
+extern struct shared_ubo *data_model_shared_ubo;
+
 typedef struct {
   char *name;
   uint32_t first;
@@ -39,19 +41,6 @@
 } data_model_t;
 extern data_model_t data_models[];
 
-#define UNIFORM_ALIGN (sizeof(float) * 4)
-#define FROM_UNIFORM_ALLOC(x) (x * UNIFORM_ALIGN)
-#define TO_UNIFORM_ALLOC(x) ((x + UNIFORM_ALIGN - 1) / UNIFORM_ALIGN)
-#define UNIFORM_SIZE (4096 * 4096)
-typedef struct {
-  VkDescriptorSet descriptor_set;
-  size_t offset;
-  size_t range;
-  size_t width;
-  struct list_head list;
-} uniform_map_t;
-extern void (*data_setup_model_instance)(uniform_map_t *uniform_map);
-
 typedef struct data_model_instance {
   char *name;
   size_t model;
@@ -59,9 +48,10 @@
   void *closure;
   struct list_head list;
   void *ubo;
-  uniform_map_t *uniform_map;
+  struct list_head *uniform_map;
 } data_model_instance_t;
 extern struct list_head data_model_instances;
+extern void (*data_setup_model_instance)(data_model_instance_t *inst);
 
 typedef struct {
   struct {
@@ -84,4 +74,17 @@
 } data_material_t;
 extern const data_material_t data_materials[];
 
+#define UNIFORM_ALIGN (sizeof(float) * 4)
+#define FROM_UNIFORM_ALLOC(x) (x * UNIFORM_ALIGN)
+#define TO_UNIFORM_ALLOC(x) ((x + UNIFORM_ALIGN - 1) / UNIFORM_ALIGN)
+#define UNIFORM_SIZE (4096 * 4096)
+#define SHARED_UNIFORM_SIZE (4096 * 32)
+typedef struct {
+  VkDescriptorSet descriptor_set;
+  size_t offset;
+  size_t range;
+  size_t width;
+  struct list_head list;
+} uniform_map_t;
+
 #endif
diff -bNur 0006multi-model/libdata.c 0007shared-ubo/libdata.c
--- 0006multi-model/libdata.c	2019-03-03 15:08:52.168916321 -0600
+++ 0007shared-ubo/libdata.c	2019-03-03 15:08:52.172915452 -0600
@@ -13,6 +13,15 @@
         }
 }
 
+typedef struct shared_ubo
+{
+        mat4 vp;
+        vec3 lightPos;
+        float pada;
+        vec3 viewPos;
+        float padb;
+} shared_ubo_t;
+
 float center_dir = 0;
 
 GLFWwindow *data_window = NULL;
@@ -42,6 +51,9 @@
         glm_mat4_copy(rot0, *model);
 }
 
+#define SUBO data_model_shared_ubo
+struct shared_ubo *SUBO = NULL;
+
 typedef struct
 {
         data_model_instance_t obj, other_obj;
@@ -81,7 +93,7 @@
 };
 
 inline static void split_map(size_t size, uniform_map_t *map,
-                             uniform_map_t **ptr)
+                             struct list_head **ptr)
 {
         uniform_map_t *this_map;
         this_map = malloc(sizeof(uniform_map_t));
@@ -94,7 +106,7 @@
                 this_map->width = map->width - map->range;
                 map->width = map->range;
                 list_add(&this_map->list, map->list.next);
-                *ptr = this_map;
+                *ptr = &this_map->list;
         }
         else
         {
@@ -102,12 +114,12 @@
                 map->offset += this_map->width = this_map->range = size;
                 map->width -= size;
                 list_add(&this_map->list, &map->list);
-                *ptr = this_map;
+                *ptr = &this_map->list;
         }
 }
 
+void (*data_setup_model_instance)(data_model_instance_t *inst);
 uintptr_t data_uniform_ptr = 0;
-void (*data_setup_model_instance)(uniform_map_t *uniform_map);
 inline static void setup_model_instance(data_model_instance_t *inst)
 {
         size_t size = TO_UNIFORM_ALLOC(
@@ -131,14 +143,14 @@
                         if ((!map->range) && (free >= size) && (size * 2 > free))
                         {
                                 map->range = size;
-                                inst->uniform_map = map;
-                                data_setup_model_instance(inst->uniform_map);
+                                inst->uniform_map = &map->list;
+                                data_setup_model_instance(inst);
                                 break;
                         }
                         else if (size < free)
                         {
                                 split_map(size, map, &inst->uniform_map);
-                                data_setup_model_instance(inst->uniform_map);
+                                data_setup_model_instance(inst);
                                 break;
                         }
                         else if (size < free + contigious)
@@ -148,22 +160,21 @@
                 }
         }
         assert(inst->uniform_map && "Out of uniform space.");
-        inst->ubo = (void *)(FROM_UNIFORM_ALLOC(inst->uniform_map->offset) +
+        inst->ubo = (void *)(FROM_UNIFORM_ALLOC(list_entry(inst->uniform_map,
+                                                           uniform_map_t, list)
+                                                    ->offset) +
                              data_uniform_ptr);
 }
 
 mat4 projection;
 mat4 view;
-inline static void update_vp(material_0_ubo_t *ubo_0, material_0_ubo_t *ubo_1)
+inline static void update_vp()
 {
-        glm_vec_copy(ubo_0->viewPos, ubo_1->viewPos);
-
-        glm_lookat(ubo_0->viewPos,
-                   (vec3){ubo_0->viewPos[0] + sinf(center_dir), ubo_0->viewPos[1],
-                          ubo_0->viewPos[2] + cosf(center_dir)},
+        glm_lookat(SUBO->viewPos,
+                   (vec3){SUBO->viewPos[0] + sinf(center_dir), SUBO->viewPos[1],
+                          SUBO->viewPos[2] + cosf(center_dir)},
                    GLM_YUP, view);
-        glm_mat4_mul(projection, view, ubo_0->vp);
-        glm_mat4_copy(ubo_0->vp, ubo_1->vp);
+        glm_mat4_mul(projection, view, SUBO->vp);
 }
 
 /*
@@ -187,14 +198,16 @@
         {
                 static const material_0_ubo_t empty_data_material_ubo_s;
                 *ubo_0 = empty_data_material_ubo_s;
+                static const shared_ubo_t empty_shared_ubo_s;
+                *SUBO = empty_shared_ubo_s;
         }
         glm_mat4_copy(GLM_MAT4_IDENTITY, ubo_0->bones[0]);
-        ubo_0->lightPos[0] = 0.0f;
-        ubo_0->lightPos[1] = 250.0f;
-        ubo_0->lightPos[2] = -250.0f;
-        ubo_0->viewPos[0] = 0.0f;
-        ubo_0->viewPos[1] = 0.0f;
-        ubo_0->viewPos[2] = -2.0f;
+        SUBO->lightPos[0] = 0.0f;
+        SUBO->lightPos[1] = 250.0f;
+        SUBO->lightPos[2] = -250.0f;
+        SUBO->viewPos[0] = 0.0f;
+        SUBO->viewPos[1] = 0.0f;
+        SUBO->viewPos[2] = -3.0f;
 
         glm_mat4_copy(GLM_MAT4_IDENTITY, ubo_0->model);
 
@@ -212,7 +225,7 @@
                      oglproj, projection);
 #endif
 
-        update_vp(ubo_0, ubo_1);
+        update_vp();
 
         *ubo_1 = *ubo_0;
         glm_rotate_y(GLM_MAT4_IDENTITY, CGLM_PI / 2, ubo_1->model);
@@ -220,8 +233,7 @@
         previous_frame = glfwGetTime();
 }
 
-inline static void handle_input(double this_frame, material_0_ubo_t *ubo_0,
-                                material_0_ubo_t *ubo_1)
+inline static void handle_input(double this_frame)
 {
         float diagnal2 = 1;
         bool need_lookat = false;
@@ -234,8 +246,8 @@
                                                                        : previous_frame - this_frame);
                 if (GET_KEY(GLFW_KEY_R) ^ GET_KEY(GLFW_KEY_V))
                         diagnal2 = 0.70710678119f;
-                ubo_0->viewPos[0] += sinf(center_dir) * dist * diagnal2;
-                ubo_0->viewPos[2] += cosf(center_dir) * dist * diagnal2;
+                SUBO->viewPos[0] += sinf(center_dir) * dist * diagnal2;
+                SUBO->viewPos[2] += cosf(center_dir) * dist * diagnal2;
                 need_lookat = true;
         }
 
@@ -250,12 +262,12 @@
         {
                 double dist = 1.5 * (GET_KEY(GLFW_KEY_R) ? this_frame - previous_frame
                                                          : previous_frame - this_frame);
-                ubo_0->viewPos[1] += dist * diagnal2;
+                SUBO->viewPos[1] += dist * diagnal2;
                 need_lookat = true;
         }
 
         if (need_lookat)
-                update_vp(ubo_0, ubo_1);
+                update_vp();
 }
 
 void _glm_atan3(vec3 zvec, float zopposite, float zadjacent, vec3 rot)
@@ -342,16 +354,9 @@
 
 void data_update()
 {
-        material_0_ubo_t *ubo_0 = list_entry(data_model_instances.next,
-                                             data_model_instance_t, list)
-                                      ->ubo,
-                         *ubo_1 = list_entry(data_model_instances.next->next,
-                                             data_model_instance_t, list)
-                                      ->ubo;
-
         double this_frame = glfwGetTime();
 
-        handle_input(this_frame, ubo_0, ubo_1);
+        handle_input(this_frame);
 
         data_model_instance_t *ptr;
         list_for_each_entry(ptr, &data_model_instances, list)
@@ -359,6 +364,7 @@
 
         if (0)
         {
+                material_0_ubo_t *ubo_0 = model_instance.obj.ubo;
                 mat4 model;
                 glm_mat4_copy(ubo_0->model, model);
                 glm_rotate_y(model, this_frame - previous_frame, ubo_0->model);
diff -bNur 0006multi-model/vulkan.c 0007shared-ubo/vulkan.c
--- 0006multi-model/vulkan.c	2019-03-07 12:31:46.183440860 -0600
+++ 0007shared-ubo/vulkan.c	2019-03-03 15:08:52.472850282 -0600
@@ -1,7 +1,6 @@
 #include "data.h"
 #include <assert.h>
 #include <string.h>
-#include <vk_mem_alloc.h>
 
 VkExtent2D extent = {.width = 800, .height = 600};
 
@@ -11,27 +10,26 @@
 VkInstance instance = VK_NULL_HANDLE;
 VkSurfaceKHR surface = VK_NULL_HANDLE;
 VkDevice device = VK_NULL_HANDLE;
-VmaAllocator allocator;
 VkSwapchainKHR swapchain = VK_NULL_HANDLE;
 VkImage swapchain_images[3] = {VK_NULL_HANDLE, VK_NULL_HANDLE, VK_NULL_HANDLE};
 VkImageView swapchain_image_views[3] = {VK_NULL_HANDLE, VK_NULL_HANDLE,
                                         VK_NULL_HANDLE};
 VkImage depth_stencil_image = VK_NULL_HANDLE;
-VmaAllocation depth_stencil_image_allocation = NULL;
+VkDeviceMemory depth_stencil_image_memory = VK_NULL_HANDLE;
 VkImageView depth_stencil_image_view = VK_NULL_HANDLE;
 VkRenderPass render_pass = VK_NULL_HANDLE;
 VkFramebuffer framebuffers[3] = {VK_NULL_HANDLE, VK_NULL_HANDLE,
                                  VK_NULL_HANDLE};
 VkBuffer uniform_buffer = VK_NULL_HANDLE;
-VmaAllocation uniform_buffer_allocation = NULL;
+VkDeviceMemory uniform_buffer_memmory = VK_NULL_HANDLE;
 VkDescriptorSetLayout descriptor_set_layout = VK_NULL_HANDLE;
 VkDescriptorPool descriptor_pool = VK_NULL_HANDLE;
 VkPipelineLayout pipeline_layout = VK_NULL_HANDLE;
 VkSampler texture_image_sampler;
 VkBuffer vertex_buffer = VK_NULL_HANDLE;
-VmaAllocation vertex_buffer_allocation = NULL;
+VkDeviceMemory vertex_buffer_memmory = VK_NULL_HANDLE;
 VkBuffer index_buffer = VK_NULL_HANDLE;
-VmaAllocation index_buffer_allocation = NULL;
+VkDeviceMemory index_buffer_memmory = VK_NULL_HANDLE;
 VkImageView *texture_image_views;
 VkCommandPool command_pool = VK_NULL_HANDLE;
 VkSemaphore wait_semaphore = VK_NULL_HANDLE;
@@ -84,7 +82,8 @@
 }
 
 inline static void
-find_device_surface(VkPhysicalDevice *gpu)
+find_device_surface(VkPhysicalDevice *gpu,
+                    VkPhysicalDeviceMemoryProperties *gpu_memory_properties)
 {
         uint32_t gpu_count;
         VkResult err;
@@ -115,6 +114,8 @@
                                 glfwGetWindowSize(data_window, &width, &height);
                                 extent = (VkExtent2D){.width = width, .height = height};
                         }
+
+                        vkGetPhysicalDeviceMemoryProperties(*gpu, gpu_memory_properties);
                 }
                 assert((*gpu != VK_NULL_HANDLE) &&
                        "Vulkan ERROR: Usable device not found.");
@@ -339,19 +340,6 @@
                     "stencil format.");
 }
 
-inline static void create_vma(VkPhysicalDevice gpu)
-{
-        VmaAllocatorCreateInfo allocatorInfo;
-        static const VmaAllocatorCreateInfo EmptyVmaAllocatorCreateInfo;
-        allocatorInfo = EmptyVmaAllocatorCreateInfo;
-        allocatorInfo.physicalDevice = gpu;
-        allocatorInfo.device = device;
-
-        VkResult err;
-        err = vmaCreateAllocator(&allocatorInfo, &allocator);
-        assert((err == VK_SUCCESS) && "vmaCreateAllocator: Faileld.");
-}
-
 inline static void create_depth_stencil_image(VkFormat depth_stencil_format)
 {
         VkImageCreateInfo image_create_info;
@@ -373,16 +361,48 @@
         image_create_info.pQueueFamilyIndices = NULL;
         image_create_info.initialLayout = VK_IMAGE_LAYOUT_UNDEFINED;
 
-        VmaAllocationCreateInfo alloc_create_info;
-        static const VmaAllocationCreateInfo EmptyVmaAllocationCreateInfo;
-        alloc_create_info = EmptyVmaAllocationCreateInfo;
-        alloc_create_info.usage = VMA_MEMORY_USAGE_GPU_ONLY;
-
         VkResult err;
-        err = vmaCreateImage(allocator, &image_create_info, &alloc_create_info, &depth_stencil_image, &depth_stencil_image_allocation, NULL);
+        err = vkCreateImage(device, &image_create_info, NULL, &depth_stencil_image);
         assert((err == VK_SUCCESS) && "vkCreateImage: Failed depth stencil.");
 }
 
+inline static void allocate_depth_stencil_memory(
+    VkPhysicalDeviceMemoryProperties gpu_memory_properties)
+{
+        VkMemoryRequirements image_memory_requirements;
+        vkGetImageMemoryRequirements(device, depth_stencil_image,
+                                     &image_memory_requirements);
+
+        VkMemoryAllocateInfo memory_allocate_info;
+        static const VkMemoryAllocateInfo EmptyVkMemoryAllocateInfo;
+        memory_allocate_info = EmptyVkMemoryAllocateInfo;
+        memory_allocate_info.sType = VK_STRUCTURE_TYPE_MEMORY_ALLOCATE_INFO;
+        memory_allocate_info.allocationSize = image_memory_requirements.size;
+
+        memory_allocate_info.memoryTypeIndex = UINT32_MAX;
+        for (size_t i = 0; i < gpu_memory_properties.memoryTypeCount; i++)
+        {
+                if ((image_memory_requirements.memoryTypeBits & (1 << i)) &&
+                    ((gpu_memory_properties.memoryTypes[i].propertyFlags &
+                      VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT) ==
+                     VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT))
+                {
+                        memory_allocate_info.memoryTypeIndex = i;
+                        break;
+                }
+        }
+        assert((memory_allocate_info.memoryTypeIndex != UINT32_MAX) &&
+               "Couldn't locate depth stencil memory.");
+
+        VkResult err;
+        err = vkAllocateMemory(device, &memory_allocate_info, NULL,
+                               &depth_stencil_image_memory);
+        assert((err == VK_SUCCESS) && "vkAllocateMemory: Failed depth stencil.");
+        err = vkBindImageMemory(device, depth_stencil_image,
+                                depth_stencil_image_memory, 0);
+        assert((err == VK_SUCCESS) && "vkBindImageMemory: Failed depth stencil.");
+}
+
 inline static void
 create_depth_stencil_image_view(VkFormat depth_stencil_format)
 {
@@ -411,10 +431,12 @@
 }
 
 inline static void setup_depth_stencil_image(
-    VkPhysicalDevice gpu, VkFormat *depth_stencil_format)
+    VkPhysicalDevice gpu, VkFormat *depth_stencil_format,
+    VkPhysicalDeviceMemoryProperties gpu_memory_properties)
 {
         choose_depth_stencil_format(gpu, depth_stencil_format);
         create_depth_stencil_image(*depth_stencil_format);
+        allocate_depth_stencil_memory(gpu_memory_properties);
         create_depth_stencil_image_view(*depth_stencil_format);
 }
 
@@ -508,35 +530,69 @@
         static const VkBufferCreateInfo EmptyVkBufferCreateInfo;
         buffer_info_create = EmptyVkBufferCreateInfo;
         buffer_info_create.sType = VK_STRUCTURE_TYPE_BUFFER_CREATE_INFO;
-        buffer_info_create.size = UNIFORM_SIZE;
+        buffer_info_create.size = UNIFORM_SIZE + SHARED_UNIFORM_SIZE;
         buffer_info_create.usage = VK_BUFFER_USAGE_UNIFORM_BUFFER_BIT;
         buffer_info_create.sharingMode = VK_SHARING_MODE_EXCLUSIVE;
 
-        VmaAllocationCreateInfo alloc_create_info;
-        static const VmaAllocationCreateInfo EmptyVmaAllocationCreateInfo;
-        alloc_create_info = EmptyVmaAllocationCreateInfo;
-        alloc_create_info.requiredFlags = VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT | VK_MEMORY_PROPERTY_HOST_COHERENT_BIT;
-        alloc_create_info.preferredFlags = VK_MEMORY_PROPERTY_HOST_CACHED_BIT;
-
         VkResult err;
-        err = vmaCreateBuffer(allocator, &buffer_info_create, &alloc_create_info,
-                              &uniform_buffer, &uniform_buffer_allocation, NULL);
+        err = vkCreateBuffer(device, &buffer_info_create, NULL, &uniform_buffer);
         assert((err == VK_SUCCESS) && "vkCreateBuffer: Failed uniform buffer.");
 }
 
+inline static void allocate_uniform_buffer(
+    VkPhysicalDeviceMemoryProperties gpu_memory_properties)
+{
+        VkMemoryRequirements mememory_requirements;
+        vkGetBufferMemoryRequirements(device, uniform_buffer, &mememory_requirements);
+
+        VkMemoryAllocateInfo allocate_info;
+        static const VkMemoryAllocateInfo EmptyVkMemoryAllocateInfo;
+        allocate_info = EmptyVkMemoryAllocateInfo;
+        allocate_info.sType = VK_STRUCTURE_TYPE_MEMORY_ALLOCATE_INFO;
+        allocate_info.allocationSize = mememory_requirements.size;
+
+        allocate_info.memoryTypeIndex = UINT32_MAX;
+        for (size_t i = 0; i < gpu_memory_properties.memoryTypeCount; ++i)
+        {
+                if ((mememory_requirements.memoryTypeBits & (1 << i)) &&
+                    ((gpu_memory_properties.memoryTypes[i].propertyFlags &
+                      (VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT |
+                       VK_MEMORY_PROPERTY_HOST_COHERENT_BIT)) ==
+                     (VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT |
+                      VK_MEMORY_PROPERTY_HOST_COHERENT_BIT)))
+                {
+                        allocate_info.memoryTypeIndex = i;
+                        break;
+                }
+        }
+        assert((allocate_info.memoryTypeIndex != UINT32_MAX) &&
+               "Failed to find suitable memory type for uniform.");
+
+        VkResult err;
+        err = vkAllocateMemory(device, &allocate_info, NULL, &uniform_buffer_memmory);
+        assert((err == VK_SUCCESS) && "vkAllocateMemory: Failed uniform buffer.");
+
+        err = vkBindBufferMemory(device, uniform_buffer, uniform_buffer_memmory, 0);
+        assert((err == VK_SUCCESS) && "vkBindBufferMemory: Failed uniform buffer.");
+}
+
 inline static void
-setup_uniform_buffer()
+setup_uniform_buffer(VkPhysicalDeviceMemoryProperties gpu_memory_properties)
 {
         create_uniform_buffer();
+        allocate_uniform_buffer(gpu_memory_properties);
 
         VkResult err;
-        err = vmaMapMemory(allocator, uniform_buffer_allocation, (void **)&data_uniform_ptr);
+        err = vkMapMemory(device, uniform_buffer_memmory, 0,
+                          UNIFORM_SIZE + SHARED_UNIFORM_SIZE, 0,
+                          (void **)&data_uniform_ptr);
         assert((err == VK_SUCCESS) && "vkMapMemory: Failed uniform buffer.");
+        data_model_shared_ubo = (struct shared_ubo *)(UNIFORM_SIZE + data_uniform_ptr);
 }
 
 inline static void create_descriptor_set_layout()
 {
-        VkDescriptorSetLayoutBinding set_layout_bindings[2];
+        VkDescriptorSetLayoutBinding set_layout_bindings[3];
         static const VkDescriptorSetLayoutBinding EmptyVkDescriptorSetLayoutBinding;
         set_layout_bindings[0] = EmptyVkDescriptorSetLayoutBinding;
         set_layout_bindings[0].descriptorType = VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER;
@@ -544,6 +600,9 @@
         set_layout_bindings[0].binding = 0;
         set_layout_bindings[0].descriptorCount = 1;
 
+        set_layout_bindings[2] = set_layout_bindings[0];
+        set_layout_bindings[2].binding = 2;
+
         set_layout_bindings[1] = EmptyVkDescriptorSetLayoutBinding;
         set_layout_bindings[1].descriptorType =
             VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER;
@@ -612,23 +671,31 @@
 
 inline static void update_descriptor_set(uniform_map_t *map)
 {
-        VkDescriptorBufferInfo uniform_descriptors[1];
+        VkDescriptorBufferInfo uniform_descriptors[2];
         static const VkDescriptorBufferInfo EmptyVkDescriptorBufferInfo;
         uniform_descriptors[0] = EmptyVkDescriptorBufferInfo;
         uniform_descriptors[0].buffer = uniform_buffer;
         uniform_descriptors[0].offset = FROM_UNIFORM_ALLOC(map->offset);
         uniform_descriptors[0].range = FROM_UNIFORM_ALLOC(map->range);
 
-        VkWriteDescriptorSet write_descriptor_sets[2];
+        uniform_descriptors[1] = uniform_descriptors[0];
+        uniform_descriptors[1].offset = UNIFORM_SIZE;
+        uniform_descriptors[1].range = SHARED_UNIFORM_SIZE;
+
+        VkWriteDescriptorSet write_descriptor_sets[3];
         static const VkWriteDescriptorSet EmptyVkWriteDescriptorSet;
         write_descriptor_sets[0] = EmptyVkWriteDescriptorSet;
         write_descriptor_sets[0].sType = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET;
         write_descriptor_sets[0].dstSet = map->descriptor_set;
         write_descriptor_sets[0].descriptorType = VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER;
         write_descriptor_sets[0].dstBinding = 0;
-        write_descriptor_sets[0].pBufferInfo = uniform_descriptors;
+        write_descriptor_sets[0].pBufferInfo = &uniform_descriptors[0];
         write_descriptor_sets[0].descriptorCount = 1;
 
+        write_descriptor_sets[2] = write_descriptor_sets[0];
+        write_descriptor_sets[2].dstBinding = 2;
+        write_descriptor_sets[2].pBufferInfo = &uniform_descriptors[1];
+
         VkDescriptorImageInfo image_info;
         static const VkDescriptorImageInfo EmptyVkDescriptorImageInfo;
         image_info = EmptyVkDescriptorImageInfo;
@@ -650,11 +717,13 @@
             write_descriptor_sets, 0, NULL);
 }
 
-void setup_model_instance(uniform_map_t *uniform_map)
+void setup_model_instance(data_model_instance_t *inst)
 {
-        if (uniform_map->descriptor_set == VK_NULL_HANDLE)
-                allocate_descriptor_set(&uniform_map->descriptor_set);
-        update_descriptor_set(uniform_map);
+        uniform_map_t *this_map;
+        this_map = list_entry(inst->uniform_map, uniform_map_t, list);
+        if (this_map->descriptor_set == VK_NULL_HANDLE)
+                allocate_descriptor_set(&this_map->descriptor_set);
+        update_descriptor_set(this_map);
 }
 
 inline static void create_pipeline_layout()
@@ -718,30 +787,63 @@
         buffer_info_create.usage = VK_BUFFER_USAGE_VERTEX_BUFFER_BIT;
         buffer_info_create.sharingMode = VK_SHARING_MODE_EXCLUSIVE;
 
-        VmaAllocationCreateInfo alloc_create_info;
-        static const VmaAllocationCreateInfo EmptyVmaAllocationCreateInfo;
-        alloc_create_info = EmptyVmaAllocationCreateInfo;
-        alloc_create_info.usage = VMA_MEMORY_USAGE_CPU_TO_GPU;
+        VkResult err;
+        err = vkCreateBuffer(device, &buffer_info_create, NULL, &vertex_buffer);
+        assert((err == VK_SUCCESS) && "vkCreateBuffer: Failed vertex buffer.");
+}
+
+inline static void
+allocate_vertex_buffer(VkPhysicalDeviceMemoryProperties gpu_memory_properties)
+{
+        VkMemoryRequirements mememory_requirements;
+        vkGetBufferMemoryRequirements(device, vertex_buffer, &mememory_requirements);
+
+        VkMemoryAllocateInfo allocate_info;
+        static const VkMemoryAllocateInfo EmptyVkMemoryAllocateInfo;
+        allocate_info = EmptyVkMemoryAllocateInfo;
+        allocate_info.sType = VK_STRUCTURE_TYPE_MEMORY_ALLOCATE_INFO;
+        allocate_info.allocationSize = mememory_requirements.size;
+
+        allocate_info.memoryTypeIndex = UINT32_MAX;
+        for (size_t i = 0; i < gpu_memory_properties.memoryTypeCount; ++i)
+        {
+                if ((mememory_requirements.memoryTypeBits & (1 << i)) &&
+                    ((gpu_memory_properties.memoryTypes[i].propertyFlags &
+                      (VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT |
+                       VK_MEMORY_PROPERTY_HOST_COHERENT_BIT)) ==
+                     (VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT |
+                      VK_MEMORY_PROPERTY_HOST_COHERENT_BIT)))
+                {
+                        allocate_info.memoryTypeIndex = i;
+                        break;
+                }
+        }
+        assert((allocate_info.memoryTypeIndex != UINT32_MAX) &&
+               "Failed to find suitable memory type for vertex.");
 
         VkResult err;
-        err = vmaCreateBuffer(allocator, &buffer_info_create, &alloc_create_info, &vertex_buffer, &vertex_buffer_allocation, NULL);
-        assert((err == VK_SUCCESS) && "vmaCreateBuffer: Failed vertex buffer.");
+        err = vkAllocateMemory(device, &allocate_info, NULL, &vertex_buffer_memmory);
+        assert((err == VK_SUCCESS) && "vkAllocateMemory: Failed vertex buffer.");
+
+        err = vkBindBufferMemory(device, vertex_buffer, vertex_buffer_memmory, 0);
+        assert((err == VK_SUCCESS) && "vkBindBufferMemory: Failed vertex buffer.");
 }
 
 inline static void
-setup_vertex_buffer()
+setup_vertex_buffer(VkPhysicalDeviceMemoryProperties gpu_memory_properties)
 {
         create_vertex_buffer();
+        allocate_vertex_buffer(gpu_memory_properties);
 
         void *data;
         VkResult err;
-        err = vmaMapMemory(allocator, vertex_buffer_allocation, &data);
-        assert((err == VK_SUCCESS) && "vmaMapMemory: Failed vertex buffer.");
+        err = vkMapMemory(device, vertex_buffer_memmory, 0, data_model_vertex_size, 0,
+                          &data);
+        assert((err == VK_SUCCESS) && "vkMapMemory: Failed vertex buffer.");
 
         memcpy(data, data_model_vertex, data_model_vertex_size);
 
-        vmaUnmapMemory(allocator, vertex_buffer_allocation);
-        vmaFlushAllocation(allocator, vertex_buffer_allocation, 0, data_model_vertex_size);
+        vkUnmapMemory(device, vertex_buffer_memmory);
 }
 
 inline static void create_index_buffer()
@@ -754,33 +856,66 @@
         buffer_info_create.usage = VK_BUFFER_USAGE_INDEX_BUFFER_BIT;
         buffer_info_create.sharingMode = VK_SHARING_MODE_EXCLUSIVE;
 
-        VmaAllocationCreateInfo alloc_create_info;
-        static const VmaAllocationCreateInfo EmptyVmaAllocationCreateInfo;
-        alloc_create_info = EmptyVmaAllocationCreateInfo;
-        alloc_create_info.usage = VMA_MEMORY_USAGE_CPU_TO_GPU;
+        VkResult err;
+        err = vkCreateBuffer(device, &buffer_info_create, NULL, &index_buffer);
+        assert((err == VK_SUCCESS) && "vkCreateBuffer: Failed index buffer.");
+}
+
+inline static void
+allocate_index_buffer(VkPhysicalDeviceMemoryProperties gpu_memory_properties)
+{
+        VkMemoryRequirements mememory_requirements;
+        vkGetBufferMemoryRequirements(device, index_buffer, &mememory_requirements);
+
+        VkMemoryAllocateInfo allocate_info;
+        static const VkMemoryAllocateInfo EmptyVkMemoryAllocateInfo;
+        allocate_info = EmptyVkMemoryAllocateInfo;
+        allocate_info.sType = VK_STRUCTURE_TYPE_MEMORY_ALLOCATE_INFO;
+        allocate_info.allocationSize = mememory_requirements.size;
+
+        allocate_info.memoryTypeIndex = UINT32_MAX;
+        for (size_t i = 0; i < gpu_memory_properties.memoryTypeCount; ++i)
+        {
+                if ((mememory_requirements.memoryTypeBits & (1 << i)) &&
+                    ((gpu_memory_properties.memoryTypes[i].propertyFlags &
+                      (VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT |
+                       VK_MEMORY_PROPERTY_HOST_COHERENT_BIT)) ==
+                     (VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT |
+                      VK_MEMORY_PROPERTY_HOST_COHERENT_BIT)))
+                {
+                        allocate_info.memoryTypeIndex = i;
+                        break;
+                }
+        }
+        assert((allocate_info.memoryTypeIndex != UINT32_MAX) &&
+               "Failed to find suitable memory type for index.");
 
         VkResult err;
-        err = vmaCreateBuffer(allocator, &buffer_info_create, &alloc_create_info, &index_buffer, &index_buffer_allocation, NULL);
-        assert((err == VK_SUCCESS) && "vmaCreateBuffer: Failed index buffer.");
+        err = vkAllocateMemory(device, &allocate_info, NULL, &index_buffer_memmory);
+        assert((err == VK_SUCCESS) && "vkAllocateMemory: Failed index buffer.");
+
+        err = vkBindBufferMemory(device, index_buffer, index_buffer_memmory, 0);
+        assert((err == VK_SUCCESS) && "vkBindBufferMemory: Failed index buffer.");
 }
 
 inline static void
-setup_index_buffer()
+setup_index_buffer(VkPhysicalDeviceMemoryProperties gpu_memory_properties)
 {
         create_index_buffer();
+        allocate_index_buffer(gpu_memory_properties);
 
         void *data;
         VkResult err;
-        err = vmaMapMemory(allocator, index_buffer_allocation, &data);
-        assert((err == VK_SUCCESS) && "vmaMapMemory: Failed index buffer.");
+        err = vkMapMemory(device, index_buffer_memmory, 0, data_model_index_size, 0,
+                          &data);
+        assert((err == VK_SUCCESS) && "vkMapMemory: Failed index buffer.");
 
         memcpy(data, data_model_index, data_model_index_size);
 
-        vmaUnmapMemory(allocator, index_buffer_allocation);
-        vmaFlushAllocation(allocator, index_buffer_allocation, 0, data_model_index_size);
+        vkUnmapMemory(device, index_buffer_memmory);
 }
 
-inline static void create_texture_images(VkImage *texture_images, VmaAllocation *texture_image_allocations)
+inline static void create_texture_images(VkImage *texture_images)
 {
         VkImageCreateInfo image_create_info;
         static const VkImageCreateInfo EmptyVkImageViewCreateInfo;
@@ -801,30 +936,65 @@
         image_create_info.pQueueFamilyIndices = NULL;
         image_create_info.initialLayout = VK_IMAGE_LAYOUT_PREINITIALIZED;
 
-        VmaAllocationCreateInfo alloc_create_info;
-        static const VmaAllocationCreateInfo EmptyVmaAllocationCreateInfo;
-        alloc_create_info = EmptyVmaAllocationCreateInfo;
-        alloc_create_info.usage = VMA_MEMORY_USAGE_CPU_TO_GPU;
-
         VkResult err;
-        err = vmaCreateImage(allocator, &image_create_info, &alloc_create_info, &texture_images[0], &texture_image_allocations[0], NULL);
+        err = vkCreateImage(device, &image_create_info, NULL, &texture_images[0]);
         assert((err == VK_SUCCESS) && "vkCreateImage: Failed texture.");
 }
 
 inline static void
-setup_texture_images(VkImage *texture_images, VmaAllocation *texture_image_allocations)
-{
-        create_texture_images(texture_images, texture_image_allocations);
+allocate_texture_image(VkImage texture_image,
+                       VkPhysicalDeviceMemoryProperties gpu_memory_properties,
+                       VkDeviceMemory *texture_image_memory)
+{
+        VkMemoryAllocateInfo memory_allocate_info;
+        static const VkMemoryAllocateInfo EmptyVkMemoryAllocateInfo;
+        memory_allocate_info = EmptyVkMemoryAllocateInfo;
+        memory_allocate_info.sType = VK_STRUCTURE_TYPE_MEMORY_ALLOCATE_INFO;
+
+        VkMemoryRequirements image_memory_requirements;
+        vkGetImageMemoryRequirements(device, texture_image,
+                                     &image_memory_requirements);
+        memory_allocate_info.allocationSize = image_memory_requirements.size;
+
+        memory_allocate_info.memoryTypeIndex = UINT32_MAX;
+        for (size_t i = 0; i < gpu_memory_properties.memoryTypeCount; i++)
+        {
+                if ((image_memory_requirements.memoryTypeBits & (1 << i)) &&
+                    ((gpu_memory_properties.memoryTypes[i].propertyFlags &
+                      (VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT |
+                       VK_MEMORY_PROPERTY_HOST_COHERENT_BIT)) ==
+                     (VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT |
+                      VK_MEMORY_PROPERTY_HOST_COHERENT_BIT)))
+                {
+                        memory_allocate_info.memoryTypeIndex = i;
+                        break;
+                }
+        }
+        assert((memory_allocate_info.memoryTypeIndex != UINT32_MAX) &&
+               "Couldn't locate texture memory.");
 
-        void *data;
         VkResult err;
-        err = vmaMapMemory(allocator, texture_image_allocations[0], &data);
-        assert((err == VK_SUCCESS) && "vmaMapMemory: Failed vertex buffer.");
+        err = vkAllocateMemory(device, &memory_allocate_info, NULL,
+                               texture_image_memory);
+        assert((err == VK_SUCCESS) && "vkAllocateMemory: Failed texture.");
+        err = vkBindImageMemory(device, texture_image, *texture_image_memory, 0);
+        assert((err == VK_SUCCESS) && "vkBindImageMemory: Failed texture.");
+}
 
-        memcpy(data, data_materials[0].texture, data_materials[0].texture_size);
+inline static void
+setup_texture_images(VkImage *texture_images,
+                     VkPhysicalDeviceMemoryProperties gpu_memory_properties,
+                     VkDeviceMemory *texture_image_memorys)
+{
+        create_texture_images(texture_images);
+        allocate_texture_image(texture_images[0], gpu_memory_properties,
+                               &texture_image_memorys[0]);
 
-        vmaUnmapMemory(allocator, texture_image_allocations[0]);
-        vmaFlushAllocation(allocator, texture_image_allocations[0], 0, data_materials[0].texture_size);
+        void *data;
+        vkMapMemory(device, texture_image_memorys[0], 0,
+                    data_materials[0].texture_size, 0, &data);
+        memcpy(data, data_materials[0].texture, data_materials[0].texture_size);
+        vkUnmapMemory(device, texture_image_memorys[0]);
 }
 
 inline static void create_image_views(VkImage *texture_images)
@@ -855,9 +1025,11 @@
 
 inline static void
 setup_textures(VkImage *texture_images,
-               VmaAllocation *texture_image_allocations)
+               VkPhysicalDeviceMemoryProperties gpu_memory_properties,
+               VkDeviceMemory *texture_image_memorys)
 {
-        setup_texture_images(texture_images, texture_image_allocations);
+        setup_texture_images(texture_images, gpu_memory_properties,
+                             texture_image_memorys);
         create_image_views(texture_images);
 }
 
@@ -1045,12 +1217,13 @@
 }
 
 inline static void setup_materials(VkImage *texture_images,
-                                   VmaAllocation *texture_image_allocations,
+                                   VkPhysicalDeviceMemoryProperties gpu_memory_properties,
+                                   VkDeviceMemory *texture_image_memorys,
                                    VkShaderModule *vert_modules,
                                    VkShaderModule *frag_modules,
                                    VkPipeline *graphics_pipelines)
 {
-        setup_textures(texture_images, texture_image_allocations);
+        setup_textures(texture_images, gpu_memory_properties, texture_image_memorys);
         create_shaders(vert_modules, frag_modules);
         create_graphice_pipelines(vert_modules, frag_modules, graphics_pipelines);
 }
@@ -1241,20 +1414,23 @@
 
         vkCmdBindIndexBuffer(command_buffer, index_buffer, 0, VK_INDEX_TYPE_UINT32);
 
-        data_model_instance_t *ptr =
+        data_model_instance_t *inst =
             list_entry(data_model_instances.next, data_model_instance_t, list);
         vkCmdBindPipeline(
             command_buffer, VK_PIPELINE_BIND_POINT_GRAPHICS,
-            graphics_pipelines[data_materials[data_models[ptr->model].material]
+            graphics_pipelines[data_materials[data_models[inst->model].material]
                                    .shader]);
 
+        list_for_each_entry(inst, &data_model_instances, list)
+        {
         vkCmdBindDescriptorSets(
             command_buffer, VK_PIPELINE_BIND_POINT_GRAPHICS, pipeline_layout, 0, 1,
-            &ptr->uniform_map->descriptor_set,
+                    &list_entry(inst->uniform_map, uniform_map_t, list)->descriptor_set,
             0, NULL);
 
-        vkCmdDrawIndexed(command_buffer, data_models[ptr->model].count, 1,
-                         data_models[ptr->model].first, 0, 0);
+                vkCmdDrawIndexed(command_buffer, data_models[inst->model].count, 1,
+                                 data_models[inst->model].first, 0, 0);
+        }
 
         vkCmdEndRenderPass(command_buffer);
 
@@ -1351,7 +1527,7 @@
 }
 
 inline static void
-clean_up(VkImage *texture_images, VmaAllocation *texture_image_allocations,
+clean_up(VkImage *texture_images, VkDeviceMemory *texture_image_memorys,
          VkPipeline *graphics_pipelines, VkShaderModule *frag_modules,
          VkShaderModule *vert_modules, uint32_t swapchain_image_count)
 {
@@ -1371,11 +1547,13 @@
         vert_modules[0] = VK_NULL_HANDLE;
         vkDestroyPipelineLayout(device, pipeline_layout, NULL);
         pipeline_layout = VK_NULL_HANDLE;
-        vmaDestroyBuffer(allocator, index_buffer, index_buffer_allocation);
-        index_buffer_allocation = NULL;
+        vkFreeMemory(device, index_buffer_memmory, NULL);
+        index_buffer_memmory = VK_NULL_HANDLE;
+        vkDestroyBuffer(device, index_buffer, NULL);
         index_buffer = VK_NULL_HANDLE;
-        vmaDestroyBuffer(allocator, vertex_buffer, vertex_buffer_allocation);
-        vertex_buffer_allocation = NULL;
+        vkFreeMemory(device, vertex_buffer_memmory, NULL);
+        vertex_buffer_memmory = VK_NULL_HANDLE;
+        vkDestroyBuffer(device, vertex_buffer, NULL);
         vertex_buffer = VK_NULL_HANDLE;
         vkDestroyPipelineLayout(device, pipeline_layout, NULL);
         pipeline_layout = VK_NULL_HANDLE;
@@ -1387,18 +1565,21 @@
         texture_image_sampler = VK_NULL_HANDLE;
         vkDestroyImageView(device, texture_image_views[0], NULL);
         texture_image_views[0] = VK_NULL_HANDLE;
-        vmaDestroyImage(allocator, texture_images[0], texture_image_allocations[0]);
-        texture_image_allocations[0] = VK_NULL_HANDLE;
+        vkFreeMemory(device, texture_image_memorys[0], NULL);
+        texture_image_memorys[0] = VK_NULL_HANDLE;
+        vkDestroyImage(device, texture_images[0], NULL);
         texture_images[0] = VK_NULL_HANDLE;
-        vmaUnmapMemory(allocator, uniform_buffer_allocation);
+        vkUnmapMemory(device, uniform_buffer_memmory);
         data_model_instance_t *ptr;
         list_for_each_entry(ptr, &data_model_instances, list)
         {
                 ptr->ubo = NULL;
-                ptr->uniform_map->descriptor_set = VK_NULL_HANDLE;
+                list_entry(ptr->uniform_map, uniform_map_t, list)->descriptor_set =
+                    VK_NULL_HANDLE;
         }
-        vmaDestroyBuffer(allocator, uniform_buffer, uniform_buffer_allocation);
-        uniform_buffer_allocation = NULL;
+        vkFreeMemory(device, uniform_buffer_memmory, NULL);
+        uniform_buffer_memmory = VK_NULL_HANDLE;
+        vkDestroyBuffer(device, uniform_buffer, NULL);
         uniform_buffer = VK_NULL_HANDLE;
         for (size_t i = 0; i < swapchain_image_count; i++)
         {
@@ -1411,11 +1592,8 @@
         render_pass = VK_NULL_HANDLE;
         vkDestroyImageView(device, depth_stencil_image_view, NULL);
         depth_stencil_image_view = VK_NULL_HANDLE;
-        vmaDestroyImage(allocator, depth_stencil_image, depth_stencil_image_allocation);
-        depth_stencil_image_allocation = NULL;
-        depth_stencil_image = VK_NULL_HANDLE;
-        vmaDestroyAllocator(allocator);
-        allocator = NULL;
+        vkFreeMemory(device, depth_stencil_image_memory, NULL);
+        depth_stencil_image_memory = VK_NULL_HANDLE;
         vkDestroyImage(device, depth_stencil_image, NULL);
         depth_stencil_image = VK_NULL_HANDLE;
         vkDestroySwapchainKHR(device, swapchain, NULL);
@@ -1436,7 +1614,8 @@
 {
         init_create_window();
         VkPhysicalDevice gpu = VK_NULL_HANDLE;
-        find_device_surface(&gpu);
+        VkPhysicalDeviceMemoryProperties gpu_memory_properties;
+        find_device_surface(&gpu, &gpu_memory_properties);
 
         uint32_t queue_family_index;
         create_device_queu_family(gpu, &queue_family_index);
@@ -1446,28 +1625,26 @@
         uint32_t swapchain_image_count = 2;
         setup_swapchain(gpu, surface_format, &swapchain_image_count);
 
-        create_vma(gpu);
-
         VkFormat depth_stencil_format;
-        setup_depth_stencil_image(gpu, &depth_stencil_format);
+        setup_depth_stencil_image(gpu, &depth_stencil_format, gpu_memory_properties);
         create_render_pass(depth_stencil_format, surface_format);
 
         create_framebuffers(swapchain_image_count);
 
-        setup_uniform_buffer();
+        setup_uniform_buffer(gpu_memory_properties);
         setup_descriptor_set();
 
-        setup_vertex_buffer();
-        setup_index_buffer();
+        setup_vertex_buffer(gpu_memory_properties);
+        setup_index_buffer(gpu_memory_properties);
 
         VkImage texture_images[] = {VK_NULL_HANDLE};
-        VmaAllocation texture_image_allocations[] = {VK_NULL_HANDLE};
+        VkDeviceMemory texture_image_memorys[] = {VK_NULL_HANDLE};
         VkImageView _texture_image_views[] = {VK_NULL_HANDLE};
         texture_image_views = _texture_image_views;
         VkShaderModule vert_modules[] = {VK_NULL_HANDLE};
         VkShaderModule frag_modules[] = {VK_NULL_HANDLE};
         VkPipeline graphics_pipelines[] = {VK_NULL_HANDLE};
-        setup_materials(texture_images, texture_image_allocations, vert_modules, frag_modules, graphics_pipelines);
+        setup_materials(texture_images, gpu_memory_properties, texture_image_memorys, vert_modules, frag_modules, graphics_pipelines);
 
         data_setup_model_instance = setup_model_instance;
         data_init(extent);
@@ -1475,7 +1652,7 @@
         create_command_pool(queue_family_index);
         blocking_render_loop(queue_family_index, texture_images, graphics_pipelines);
 
-        clean_up(texture_images, texture_image_allocations, graphics_pipelines,
+        clean_up(texture_images, texture_image_memorys, graphics_pipelines,
                  frag_modules, vert_modules, swapchain_image_count);
         exit(0);
 }
